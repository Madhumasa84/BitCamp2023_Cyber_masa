{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzhOar9dp4vYy1PqJtzsox",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Madhumasa84/BitCamp2023_Cyber_masa/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fk9z58ETSLzT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import timm\n",
        "import numpy as np\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "class MultiModalSyntheticDataset(Dataset):\n",
        "    def __init__(self, n=800):\n",
        "        super().__init__()\n",
        "        self.n = n\n",
        "\n",
        "        self.eeg = np.random.randn(n, 1, 64, 128).astype(np.float32)\n",
        "\n",
        "        self.face = np.random.randn(n, 3, 224, 224).astype(np.float32)\n",
        "\n",
        "        self.phys = np.random.randn(n, 128).astype(np.float32)\n",
        "\n",
        "        self.landmarks = np.random.randn(n, 68, 2).astype(np.float32)\n",
        "        # Labels (0 or 1)\n",
        "        self.labels = np.random.randint(0, 2, size=n)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"eeg\": torch.tensor(self.eeg[idx]),\n",
        "            \"face\": torch.tensor(self.face[idx]),\n",
        "            \"phys\": torch.tensor(self.phys[idx]),\n",
        "            \"landmarks\": torch.tensor(self.landmarks[idx]),\n",
        "            \"label\": torch.tensor(self.labels[idx]).long()\n",
        "        }\n",
        "\n",
        "\n",
        "class DenseNet201(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(\"densenet201\", pretrained=False, num_classes=0, in_chans=3)\n",
        "        self.fc = nn.Linear(self.model.num_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# 2.2 Swin Transformer\n",
        "class SwinTransformer(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(\n",
        "            \"swin_tiny_patch4_window7_224\",\n",
        "            pretrained=False,\n",
        "            num_classes=num_classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# 2.3 CNN + BiLSTM for physiological signals\n",
        "class CNNBiLSTM(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(1, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "\n",
        "            nn.Conv1d(32, 64, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2)\n",
        "        )\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=64,\n",
        "            hidden_size=128,\n",
        "            num_layers=1,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.cnn(x)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        o, _ = self.lstm(x)\n",
        "        o = o[:, -1, :]\n",
        "        return self.fc(o)\n",
        "\n",
        "# 2.4 GCN for facial landmarks\n",
        "class SimpleGCN(nn.Module):\n",
        "    def __init__(self, num_nodes=68, in_features=2, hidden=64, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(in_features, hidden)\n",
        "        self.fc2 = nn.Linear(hidden, hidden)\n",
        "        self.out = nn.Linear(hidden, num_classes)\n",
        "\n",
        "        # adjacency matrix (fully connected for simplicity)\n",
        "        self.adj = torch.ones(num_nodes, num_nodes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        A = self.adj.to(x.device)\n",
        "        x = F.relu(self.fc1(torch.einsum(\"ij,bjf->bif\", A, x)))\n",
        "        x = F.relu(self.fc2(torch.einsum(\"ij,bjf->bif\", A, x)))\n",
        "        x = x.mean(dim=1)\n",
        "        return self.out(x)\n",
        "\n",
        "# 2.5 Temporal Conformer\n",
        "class ConformerBlock(nn.Module):\n",
        "    def __init__(self, dim=128, heads=4):\n",
        "        super().__init__()\n",
        "        self.attn = nn.MultiheadAttention(dim, heads, batch_first=True)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(dim, dim*4),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(dim*4, dim)\n",
        "        )\n",
        "        self.norm1 = nn.LayerNorm(dim)\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.norm1(x)\n",
        "        x = x + self.attn(h, h, h)[0]\n",
        "        h = self.norm2(x)\n",
        "        x = x + self.ff(h)\n",
        "        return x\n",
        "\n",
        "class TemporalConformer(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.fc_in = nn.Linear(1, 128)\n",
        "        self.block = ConformerBlock(128)\n",
        "        self.out = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(-1)\n",
        "        x = self.fc_in(x)\n",
        "        x = self.block(x)\n",
        "        x = x.mean(dim=1)\n",
        "        return self.out(x)\n",
        "\n",
        "--\n",
        "def train(model, loader, device):\n",
        "    model.train()\n",
        "    optim = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(3):\n",
        "        total_loss = 0\n",
        "        for batch in loader:\n",
        "            x = batch[\"face\"].to(device)          # using face as default input\n",
        "            y = batch[\"label\"].to(device)\n",
        "\n",
        "            optim.zero_grad()\n",
        "            out = model(x)\n",
        "            loss = criterion(out, y)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1} Loss: {total_loss/len(loader):.4f}\")\n",
        "\n",
        "\n",
        "def evaluate(model, loader, device, model_name=\"model\"):\n",
        "    model.eval()\n",
        "    preds, trues = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            x = batch[\"face\"].to(device)\n",
        "            y = batch[\"label\"].to(device)\n",
        "\n",
        "            out = model(x)\n",
        "            p = out.argmax(dim=1)\n",
        "\n",
        "            preds.extend(p.cpu().numpy())\n",
        "            trues.extend(y.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(trues, preds)\n",
        "    print(f\"{model_name} Accuracy: {acc*100:.2f}%\")\n",
        "\n",
        "    cm = confusion_matrix(trues, preds)\n",
        "    plt.figure(figsize=(5,4))\n",
        "    sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
        "    plt.title(f\"Confusion Matrix â€“ {model_name}\")\n",
        "    plt.savefig(f\"{model_name}_cm.png\", dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Saved confusion matrix as {model_name}_cm.png\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # Dataset\n",
        "    ds = MultiModalSyntheticDataset()\n",
        "    train_loader = DataLoader(ds, batch_size=16, shuffle=True)\n",
        "    val_loader = DataLoader(ds, batch_size=16)\n",
        "\n",
        "    # ----- RUN ALL MODELS -----\n",
        "\n",
        "    print(\"\\n=== DenseNet201 ===\")\n",
        "    m1 = DenseNet201().to(device)\n",
        "    train(m1, train_loader, device)\n",
        "    evaluate(m1, val_loader, device, \"DenseNet201\")\n",
        "\n",
        "    print(\"\\n=== Swin Transformer ===\")\n",
        "    m2 = SwinTransformer().to(device)\n",
        "    train(m2, train_loader, device)\n",
        "    evaluate(m2, val_loader, device, \"SwinTransformer\")\n",
        "\n",
        "    print(\"\\n=== CNN-BiLSTM ===\")\n",
        "    m3 = CNNBiLSTM().to(device)\n",
        "    train(m3, train_loader, device)\n",
        "    evaluate(m3, val_loader, device, \"CNN_BiLSTM\")\n",
        "\n",
        "    print(\"\\n=== GCN ===\")\n",
        "    m4 = SimpleGCN().to(device)\n",
        "    train(m4, train_loader, device)\n",
        "    evaluate(m4, val_loader, device, \"GCN\")\n",
        "\n",
        "    print(\"\\n=== Conformer ===\")\n",
        "    m5 = TemporalConformer().to(device)\n",
        "    train(m5, train_loader, device)\n",
        "    evaluate(m5, val_loader, device, \"Conformer\")\n"
      ]
    }
  ]
}